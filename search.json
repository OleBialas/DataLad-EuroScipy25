[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DataLad EuroScipy 2025",
    "section": "",
    "text": "Welcome to the website for the DataLad1 tutorial at EuroScipy 2025! Here, you can access all exercise materials and slides. The rest of this page walks you through the setup process and resources for the tutorial."
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "DataLad EuroScipy 2025",
    "section": "Installation",
    "text": "Installation\nDataLad requires Git and Python 3.8 or later. All other dependencies can be installed via pip. if you want to learn more about DataLad and its dependencies, check out the handbook\n\nGit\nTo install and configure git follow these steps: - Install git https://git-scm.com/downloads - Configure your git user name: git config --global user.name \"user\" - Configure your git user email: git config --global user.email \"user@mail.com\"\n\n\nPython\nWe recommend to create a new virtual environment for this project with Python 3.8 or later. There are different ways to install the required Python packages. If you already have Python and a tool for managing environments you can just use pip install. Otherwise, follow the installation instructions for uv, pixi or conda.\n\npip\n\nRun pip install datalad datalad-next git-annex pandas seaborn\n\n\n\nuv\n\nInstall uv: https://docs.astral.sh/uv/getting-started/installation/\nClone this repo: git clone https://github.com/OleBialas/DataLad-Tutorial-EuroScipy2025\nInstall the environment: cd DataLad-Tutorial-EuroScipy2025; uv sync\nActivate the environment: .venv\\Scripts\\activate (on Windows) or source .venv/bin/activate (on Linux/macOS)\n\n\n\npixi\n\nInstall pixi: https://pixi.sh/latest/#installation\nClone this repo: git clone https://github.com/OleBialas/DataLad-Tutorial-EuroScipy2025\nInstall the environment: cd DataLad-Tutorial-EuroScipy2025; pixi install\nActivate the environment: pixi shell\n\n\n\nconda\n\nInstall conda: https://conda-forge.org/download/\nClone this repo: git clone https://github.com/OleBialas/DataLad-Tutorial-EuroScipy2025\nInstall the environment: cd DataLad-Tutorial-EuroScipy2025; conda env create -f environment.yml\nActivate the environment: conda activate datalad"
  },
  {
    "objectID": "index.html#data",
    "href": "index.html#data",
    "title": "DataLad EuroScipy 2025",
    "section": "Data",
    "text": "Data\nTo demonstrate DataLads data management capabilities, we’ll use a dataset hosted on GIN. You don’t have to download it upfront since cloning the dataset is part of the exercises. The data contains measurements from different penguin species and was originally published by Kristen B Gorman and colleagues 2."
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "DataLad EuroScipy 2025",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "DataLad EuroScipy 2025",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHalchenko et al., (2021). DataLad: distributed system for joint management of code, data, and their relationship. Journal of Open Source Software, 6(63), 3262, https://doi.org/10.21105/joss.03262.↩︎\nGorman, K. B., Williams, T. D., & Fraser, W. R. (2014). Ecological sexual dimorphism and environmental variability within a community of Antarctic penguins (genus Pygoscelis): https://doi.org/10.1371/journal.pone.0090081↩︎"
  },
  {
    "objectID": "about/michal.html",
    "href": "about/michal.html",
    "title": "Michał Szczepanik",
    "section": "",
    "text": "Michał…"
  },
  {
    "objectID": "notebooks/exercises2.html",
    "href": "notebooks/exercises2.html",
    "title": "Part 2: Tracking Changes in DataLad Datasets",
    "section": "",
    "text": "DataLad keeps track of all changes made to your dataset. In this section, you will add new content to the penguins dataset and see how these changes are tracked in the git log of your repository.\n\n\n\n\n\n\n\nCommand\nDescription\n\n\n\n\ndatalas status\nShow any untracked changes in the current dataset\n\n\ndatalad save\nSave any untracked changes in the current dataset\n\n\ndatalad save -m \"hi\"\nSave untracked changes and add the message \"hi\"\n\n\ndatalad unlock file.txt\nUnlock file.txt to make it modifiable\n\n\ngit log\nView the dataset’s history, stored in the git log\n\n\ngit log -3\nView the last 3 entries in the git log\n\n\n\n\nExercise 1 Create a new file in the penguins folder called penguin_species.txt and add the species names gentoo and adelie. Then, save the file and run datalad status to see the untracked changes.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\necho -e \"gentoo\\adelie\" &gt; penguin_species.txt\ndatalad status\n\n\n\n\n\nExercise 2 Use datalad save to save the untracked changes with the message \"list penguin species\".\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndatalad save -m \"list penguin species\"\n\n\nTotal: 0.00 datasets [00:00, ? datasets/s]\n\n\nTotal:   0%|                                    | 0.00/13.0 [00:00&lt;?, ? Bytes/s]\n\n\n                                                                                \nTotal:   0%|                                 | 0.00/1.00 [00:00&lt;?, ? datasets/s]\nTotal:   0%|                                 | 0.00/1.00 [00:00&lt;?, ? datasets/s]\n                                                                                \nadd(ok): penguin_species.txt (file)\n\n\nTotal:   0%|                                 | 0.00/1.00 [00:00&lt;?, ? datasets/s]\n                                                                                \nsave(ok): . (dataset)\n\n\nTotal: 100%|██████████████████████████| 1.00/1.00 [00:00&lt;00:00, 14.8 datasets/s]\n                                                                                \naction summary:\n\n  add (ok: 1)\n\n  save (ok: 1)\n\n\n\n\n\n\n\n\nExercise 3 View the most recent entry in the git log\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ngit log -1\n\n\ncommit 896a5af66c33cf7b76f82afb88fc0b99bb368d27 (HEAD -&gt; master)\n\nAuthor: obi &lt;ole.bialas@posteo.de&gt;\n\nDate:   Thu Jul 24 16:14:06 2025 +0200\n\n\n\n    list penguin species\n\n\n\n\n\n\n\n\nExercise 4 Use datalad unlock to unlock the penguin_species.txt file and append chinstrap to the list. Then, run datalad save again with a message to save the changes\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndatalad unlock penguin_species.txt\necho -e \"chinstrap\" &gt;&gt; pegnuin_species.txt\ndatalad save -m \"add chinstrap\"\n\n\n\n\n\nExercise 5 View the last two entries in the git log\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ngit log -2"
  },
  {
    "objectID": "notebooks/exercises2.html#modifying-a-dataset",
    "href": "notebooks/exercises2.html#modifying-a-dataset",
    "title": "Part 2: Tracking Changes in DataLad Datasets",
    "section": "",
    "text": "DataLad keeps track of all changes made to your dataset. In this section, you will add new content to the penguins dataset and see how these changes are tracked in the git log of your repository.\n\n\n\n\n\n\n\nCommand\nDescription\n\n\n\n\ndatalas status\nShow any untracked changes in the current dataset\n\n\ndatalad save\nSave any untracked changes in the current dataset\n\n\ndatalad save -m \"hi\"\nSave untracked changes and add the message \"hi\"\n\n\ndatalad unlock file.txt\nUnlock file.txt to make it modifiable\n\n\ngit log\nView the dataset’s history, stored in the git log\n\n\ngit log -3\nView the last 3 entries in the git log\n\n\n\n\nExercise 1 Create a new file in the penguins folder called penguin_species.txt and add the species names gentoo and adelie. Then, save the file and run datalad status to see the untracked changes.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\necho -e \"gentoo\\adelie\" &gt; penguin_species.txt\ndatalad status\n\n\n\n\n\nExercise 2 Use datalad save to save the untracked changes with the message \"list penguin species\".\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndatalad save -m \"list penguin species\"\n\n\nTotal: 0.00 datasets [00:00, ? datasets/s]\n\n\nTotal:   0%|                                    | 0.00/13.0 [00:00&lt;?, ? Bytes/s]\n\n\n                                                                                \nTotal:   0%|                                 | 0.00/1.00 [00:00&lt;?, ? datasets/s]\nTotal:   0%|                                 | 0.00/1.00 [00:00&lt;?, ? datasets/s]\n                                                                                \nadd(ok): penguin_species.txt (file)\n\n\nTotal:   0%|                                 | 0.00/1.00 [00:00&lt;?, ? datasets/s]\n                                                                                \nsave(ok): . (dataset)\n\n\nTotal: 100%|██████████████████████████| 1.00/1.00 [00:00&lt;00:00, 14.8 datasets/s]\n                                                                                \naction summary:\n\n  add (ok: 1)\n\n  save (ok: 1)\n\n\n\n\n\n\n\n\nExercise 3 View the most recent entry in the git log\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ngit log -1\n\n\ncommit 896a5af66c33cf7b76f82afb88fc0b99bb368d27 (HEAD -&gt; master)\n\nAuthor: obi &lt;ole.bialas@posteo.de&gt;\n\nDate:   Thu Jul 24 16:14:06 2025 +0200\n\n\n\n    list penguin species\n\n\n\n\n\n\n\n\nExercise 4 Use datalad unlock to unlock the penguin_species.txt file and append chinstrap to the list. Then, run datalad save again with a message to save the changes\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndatalad unlock penguin_species.txt\necho -e \"chinstrap\" &gt;&gt; pegnuin_species.txt\ndatalad save -m \"add chinstrap\"\n\n\n\n\n\nExercise 5 View the last two entries in the git log\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ngit log -2"
  },
  {
    "objectID": "notebooks/exercises2.html#running-scripts-with-datalad",
    "href": "notebooks/exercises2.html#running-scripts-with-datalad",
    "title": "Part 2: Tracking Changes in DataLad Datasets",
    "section": "Running Scripts with DataLad",
    "text": "Running Scripts with DataLad\nOften, we won’t edit our dataset manually but run scripts that do so. In this section you will use DataLad to run Python scripts and track the changes made by them. You are also going to use the dataset’s history to re-run the commands.\n\n\n\n\n\n\n\nCommand\nDescription\n\n\n\n\ndatalad run \"python script.py\"\nRun the python script script.py\n\n\ndatalad run --input \"data.csv\" --output \"figure.png\" \"python script.py\"\nRun script.py with input \"data.csv\" and output \"figure.png\"\n\n\ngit log\nView the dataset’s histroy stored in the git log\n\n\ndatalad rerun a268d8ca22b6\nRerun the command from the git log with the checksum starting with a268d8ca22b6e87959\n\n\ndatalad rerun --since a268d8ca22b6\nRerun ALL commands --since the one with the checksum starting with a268d8ca22b6e87959\n\n\n\n\nExercise 6 Try to run the python script in code/aggregate_culmen_data.py. What error message do you observe?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndatalad run \"python code/aggregate_culmen_data.py\"\n\nYou should see FileNotFoundError: [Errno 2] No such file or directory because the dataset does not contain the annexed content of the required files.\n\n\n\n\nExercise 7 (Put all tables in the same folder to avoid complicated glob pattern) Run the same script with the data/ folder as --input and the file \"results/penguin_culmens.csv\" as --output.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndatalad run --input \"data/\" --output \"results/penguin_culmens.csv\" \"python code/aggregate_culmen_data.py\"\n\n\n\n\n\nExercise 8 View the most recent entry in the git log\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ngit log -1\n\n\n\n\n\nExercise 9 Open the git log to find the checksum of the commit for the run command from Exercise 7 and re-run it.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIn the code below, $(git rev-parse HEAD) gets the checksum for the latest commit but you can also open git log and copy-paste the checksum.\n\ndatalad rerun $(git rev-parse HEAD)\n\n\n\n\n\nExercise 10 Run the script code/plot_culmen_length_vs_depth.py — it takes results/penguin_culmens.csv as --input and produces results/culmen_length_vs_depth.png as an output.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndatalad run --input \"results/penguin_culmens.csv\" --output \"results/culmen_length_vs_depth.png\" \"python code/plot_culmen_length_vs_depth.py\"\n\n\n\n\n\nExercise 11 Open the git log to find the checksum of the commit for the run command from Exercise 7 and re-run everything --since this commit (i.e. the data aggregation and plotting scripts).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIn the code below, $(git rev-parse HEAD) gets the checksum for the second latest commit but you can also open git log and copy-paste the checksum.\n\ndatalad rerun --since $(git rev-parse HEAD~1)"
  },
  {
    "objectID": "notebooks/exercises1.html",
    "href": "notebooks/exercises1.html",
    "title": "Part 1: Working with DataLad Datasets",
    "section": "",
    "text": "In this section, you are going to clone an existing DataLad dataset and download its contents. While the datalad API is universal, the commands for navigating the data set differ between operating systems (see table below).\n\nTerminal commands\n\n\n\n\n\n\n\nLinux/macOS\nWindows\nDescription\n\n\n\n\nls -a\ndir /a\nList the content of the current directory (including hidden files)\n\n\nls -a data\ndir /a data\nList the content of the data directory\n\n\ndu -sh\ndir /s\nGet the disk usage of the current directory\n\n\ndu -sh data\ndir /s data Get the disk usage of the data directory\n\n\n\ncd data\ncd data\nChange the directory to data\n\n\n\n\nDataLad commands\n\n\n\n\n\n\nCommand\nDescription\n\n\n\n\ndatalad clone https://example.com\nClone the data set from example.com\n\n\ndatalad get folder/\nGet the file content of the folder/\n\n\ndatalad get folder/image.png\nGet the file content of the file image.png\n\n\ndatalad drop folder/\nDrop the file content of the folder/\n\n\n\n\nExercise 1 Clone the dataset from https://gin.g-node.org/obi/penguins\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndatalad clone https://gin.g-node.org/obi/penguins\n\n\n\n\n\nExercise 2 Change the directory to penguins and list the directory’s content\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nOn Linux/macOS:\n\ncd penguins\nls -a\n\nOn Windows:\ncd pegnuins\ndir /a\n\n\n\n\nExercise 3 Check the disk usage of the penguins directory\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nOn Linux/macOS:\n\ndu -sh\n\nOn Windows:\ndir /s\n\n\n\n\nExercise 4 Get the content of the examples subdirectory\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndatalad get examples\n\n\n\n\n\nExercise 5 Check the disk usage of the penguins directory again\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nOn Linux/macOS:\n\ndu -sh\n\nOn Windows:\ndir /s\n\n\n\n\nExercise 6 Drop the content of examples/chinstrap.jpg and check the disk usage again\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndatalad drop examples/chinstrap.jpg\n\nOn Linux/macOS:\n\ndu -sh\n\nOn Windows:\ndir /s"
  },
  {
    "objectID": "notebooks/exercises1.html#consuming-existing-datasets",
    "href": "notebooks/exercises1.html#consuming-existing-datasets",
    "title": "Part 1: Working with DataLad Datasets",
    "section": "",
    "text": "In this section, you are going to clone an existing DataLad dataset and download its contents. While the datalad API is universal, the commands for navigating the data set differ between operating systems (see table below).\n\nTerminal commands\n\n\n\n\n\n\n\nLinux/macOS\nWindows\nDescription\n\n\n\n\nls -a\ndir /a\nList the content of the current directory (including hidden files)\n\n\nls -a data\ndir /a data\nList the content of the data directory\n\n\ndu -sh\ndir /s\nGet the disk usage of the current directory\n\n\ndu -sh data\ndir /s data Get the disk usage of the data directory\n\n\n\ncd data\ncd data\nChange the directory to data\n\n\n\n\nDataLad commands\n\n\n\n\n\n\nCommand\nDescription\n\n\n\n\ndatalad clone https://example.com\nClone the data set from example.com\n\n\ndatalad get folder/\nGet the file content of the folder/\n\n\ndatalad get folder/image.png\nGet the file content of the file image.png\n\n\ndatalad drop folder/\nDrop the file content of the folder/\n\n\n\n\nExercise 1 Clone the dataset from https://gin.g-node.org/obi/penguins\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndatalad clone https://gin.g-node.org/obi/penguins\n\n\n\n\n\nExercise 2 Change the directory to penguins and list the directory’s content\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nOn Linux/macOS:\n\ncd penguins\nls -a\n\nOn Windows:\ncd pegnuins\ndir /a\n\n\n\n\nExercise 3 Check the disk usage of the penguins directory\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nOn Linux/macOS:\n\ndu -sh\n\nOn Windows:\ndir /s\n\n\n\n\nExercise 4 Get the content of the examples subdirectory\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndatalad get examples\n\n\n\n\n\nExercise 5 Check the disk usage of the penguins directory again\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nOn Linux/macOS:\n\ndu -sh\n\nOn Windows:\ndir /s\n\n\n\n\nExercise 6 Drop the content of examples/chinstrap.jpg and check the disk usage again\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndatalad drop examples/chinstrap.jpg\n\nOn Linux/macOS:\n\ndu -sh\n\nOn Windows:\ndir /s"
  },
  {
    "objectID": "notebooks/exercises1.html#checking-file-identity-and-location-with-git-annex",
    "href": "notebooks/exercises1.html#checking-file-identity-and-location-with-git-annex",
    "title": "Part 1: Working with DataLad Datasets",
    "section": "Checking File Identity and Location with git-annex",
    "text": "Checking File Identity and Location with git-annex\nSince DataLad is built on top of git-annex, you can use its commands on any DataLad dataset. In this section, you’ll use git-annex to get information on the dataset and localize its file contents.\n\n\n\n\n\n\n\nCommand\nDescription\n\n\n\n\ngit annex info\nShow the git-annex information for the whole dataset\n\n\ngit annex info folder/image.png\nShow the git-annex information for the file image.png\n\n\ngit annex whereis folder/image.png\nList the repositories that have the file content for image.png\n\n\n\n\nExercise 7 Display the git annex info for the file examples/gentoo.jpg. What is the size of that file? Is it present on your machine?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ngit annex info examples/gentoo.jpg\n\nThe file is 4.81 megabtyes and it should be present since we previouslt loaded the content of the examples folder.\n\n\n\n\nExercise 8 Display the git-annex info of the whole data set. How many annexed files are there in the working tree?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ngit annex info\n\nThe nummber of annexed files is displayed in this line: annexed files in working tree: 21\n\n\n\n\nExercise 9 Use git annex whereis to list the repositories that have the file content for the image examples/gentoo.jpg.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ngit annex whereis examples/gentoo.jpg\n\n\n\n\n\nExercise 10 Use git annex whereis to list the repositories that have the file content for the table data/table_220.csv. How does this differ from the list of repositories that contain the content for gentoo.jpg?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ngit annex whereis data/table_220.csv\n\nThe table is not stored in the local repository, listed in the line marked [here]."
  },
  {
    "objectID": "notebooks/exercises3.html",
    "href": "notebooks/exercises3.html",
    "title": "Part 3: Distributing and Sharing your DataLad Dataset",
    "section": "",
    "text": "DataLad can manage multiple sibings of a dataset. In this section you are going to create a new sibling on GitHub and push the dataset to that repository. You’ll need an access token — on GitHub, go to Settings &gt; Developer Settings &gt; Personal access tokens and select Generate new token (classic) to create a token with access to your repositories.\n\n\n\n\n\n\n\nCommand\nDescription\n\n\n\n\ndatalad siblings\nList all siblings of the current dataset\n\n\ndatalad create-sibling-github myrepo\nCreate a new GitHub repo called myrepo and register it as a sibling\n\n\ndatalad push --to github\nPush the dataset --to the sibling github\n\n\n\n\nExercise 1 List all siblings of the penguins dataset\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndatalad siblings\n\n\n\n\n\nExercise 2 Create a new sibling on GitHub.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nEither run create-sibling-github and paste the token when being prompted\n\ndatalad create-sibling-github penguins\n\nOr use the --credential flag to pass the token\n\ndatalad create-sibling-github penguins --credential &lt;token&gt;\n\n\n\n\n\nExercise 3 Push the data to the GitHub remote\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndatalad push --to github\n\n\n\n\n\nExercise 4 Clone the dataset from the GitHub sibling to a new location\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndatalad clone https://github.com/OleBialas/penguins.git ~/"
  },
  {
    "objectID": "notebooks/exercises3.html#distributing-your-dataset",
    "href": "notebooks/exercises3.html#distributing-your-dataset",
    "title": "Part 3: Distributing and Sharing your DataLad Dataset",
    "section": "",
    "text": "DataLad can manage multiple sibings of a dataset. In this section you are going to create a new sibling on GitHub and push the dataset to that repository. You’ll need an access token — on GitHub, go to Settings &gt; Developer Settings &gt; Personal access tokens and select Generate new token (classic) to create a token with access to your repositories.\n\n\n\n\n\n\n\nCommand\nDescription\n\n\n\n\ndatalad siblings\nList all siblings of the current dataset\n\n\ndatalad create-sibling-github myrepo\nCreate a new GitHub repo called myrepo and register it as a sibling\n\n\ndatalad push --to github\nPush the dataset --to the sibling github\n\n\n\n\nExercise 1 List all siblings of the penguins dataset\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndatalad siblings\n\n\n\n\n\nExercise 2 Create a new sibling on GitHub.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nEither run create-sibling-github and paste the token when being prompted\n\ndatalad create-sibling-github penguins\n\nOr use the --credential flag to pass the token\n\ndatalad create-sibling-github penguins --credential &lt;token&gt;\n\n\n\n\n\nExercise 3 Push the data to the GitHub remote\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndatalad push --to github\n\n\n\n\n\nExercise 4 Clone the dataset from the GitHub sibling to a new location\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndatalad clone https://github.com/OleBialas/penguins.git ~/"
  },
  {
    "objectID": "notebooks/exercises3.html#creating-a-special-remote-for-file-content",
    "href": "notebooks/exercises3.html#creating-a-special-remote-for-file-content",
    "title": "Part 3: Distributing and Sharing your DataLad Dataset",
    "section": "Creating a Special Remote for File Content",
    "text": "Creating a Special Remote for File Content\nWhile GitHub is great for sharing, it does not allow you to store the annexed file content. In this section, you are going to create another local repository to store the file contents and link it to the GitHub sibling.\n\n\n\n\n\n\n\nCommand\nDesription\n\n\n\n\ndatalad get*\nGet the file contents for the whole dataset\n\n\ngit annex initremote usbdrive type=directory directory=~/dir encryption=none autoenable=true\nCreate a sibling called usbdrive in the directory ~/dir\n\n\ndatalad push --to usbdrive\nPush the dataset to the sibling usbdrive\n\n\ndatalad siblings configure -s github --publish-depends usbdrive\nConfigure the github sibling so the file contents are pushed to usbdrive\n\n\n\n\nExercise 5 Get the file content for the whole penguins dataset\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndatalad get *\n\n\n\n\n\nExercise 6 Create a special remote at a directory outside penguins/. Then, list all siblings to confirm the remove was created.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmkdir ~/usbdrive\ngit annex initremote usbdrive type=directory directory=~/usbdrive encryption=none autoenable=true\ndatalad siblings\n\n\n\n\n\nExercise 7 Push the data to the local remote\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndatalad push --to usbdrive\n\n\n\n\n\nExercise 8 configure the github sibling so that the publish depends on the local remote\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndatalad siblings configure -s github --publish-depends usbdrive"
  },
  {
    "objectID": "about/ole.html",
    "href": "about/ole.html",
    "title": "Ole Bialas",
    "section": "",
    "text": "Ole …"
  }
]